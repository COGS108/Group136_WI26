{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5ejZN3jm_Wl"
   },
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPThAoS9m_Wm"
   },
   "source": [
    "## Authors\n",
    "\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "- Yilin Cai: Background research,Methodology, Software, Visualization , Writing – review & editing\n",
    "- Nicole Liu: Conceptualization, Background research, Data curation, Writing – original draft\n",
    "- Xuanye Wang: Data curation, Experimental investigation, Software\n",
    "- Lianshi Deng: Analysis, Background research, Conceptualization\n",
    "- Jiangxi Fu: Data curation, Project administration, Writing – original draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIMVxYI1m_Wn"
   },
   "source": [
    "## Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWC998TVm_Wn"
   },
   "source": [
    "Is there a statistically significant difference in the unit price of clothing items associated with women compared to men — whether measured through product gender labels or buyer gender — and does this pattern hold across two independent retail datasets with different data structures and price measurement approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f6SJlKXm_Wn"
   },
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81Y8zEwyE-je"
   },
   "source": [
    "Gender-based pricing, often referred to as the “pink tax,” broadly describes price differences observed between products marketed toward women and those marketed toward men. Public discussion of the pink tax has frequently centered on consumer goods that are explicitly gender-labeled, including clothing, toys, and personal care products. Within this broader debate, clothing represents a particularly important category because apparel is commonly divided by gender and purchased repeatedly over time, making even small price differences potentially meaningful at scale.\n",
    "\n",
    "Evidence suggesting gender-based price differences in clothing is often traced to the New York City Department of Consumer Affairs (DCA) report *From Cradle to Cane* (2015). The report examined nearly 800 gendered products and found that girls’ clothing cost approximately 4% more than boys’ clothing, while women’s clothing cost about 8% more than men’s clothing on average. These findings have been widely cited in media coverage. For example, a USA TODAY article summarized the DCA results and highlighted side-by-side comparisons of clothing items—such as uniform polo shirts—priced higher when marketed toward girls or women despite appearing similar in style and quality<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1). Such reporting frames clothing price differences as part of a broader pattern of gender-based economic inequality.\n",
    "\n",
    "At the same time, critics have raised concerns about whether these observed clothing price differences are systematic or whether they result from imperfect product comparisons. A commentary from the American Enterprise Institute (AEI) argues that many claims of a clothing-based pink tax rely on isolated examples or broad category-level comparisons that may fail to control for differences in design, construction, or manufacturing costs<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). The AEI analysis emphasizes that without careful “apples-to-apples” matching, it is difficult to determine whether higher prices for women’s clothing reflect discrimination or underlying product differences. It also notes that long-run Consumer Price Index trends show men’s and boys’ apparel prices increasing faster than women’s and girls’ apparel prices, complicating claims of persistent one-sided disadvantage.\n",
    "\n",
    "Academic research provides additional context by examining gender differentiation in clothing prices at the policy level. **According to a peer review paper**, Scott (2025) analyzes gender discrimination in global clothing tariffs using World Trade Organization data covering more than 150 countries and multiple decades<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). The study finds that most countries impose identical import tariffs on men’s and women’s clothing. When tariff differences do exist, they are inconsistent in direction—sometimes disadvantaging women and sometimes disadvantaging men—and overall conclusions about gender bias are highly sensitive to a small number of outlier countries. These findings suggest that gender-based differences in clothing prices are not systematically embedded in trade policy, underscoring the importance of analyzing retail-level pricing data directly.\n",
    "\n",
    "While not focused on clothing, research on personal care products helps clarify how methodological choices shape conclusions about gender-based pricing. **According to a peer review paper**, Moshary, Tuchman, and Vajravelu (2023) analyze U.S. consumer packaged goods and find that although women’s products appear more expensive in aggregate, these gaps largely disappear when comparisons are restricted to products with similar ingredients from the same manufacturer<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4). Although this study does not examine apparel, it demonstrates that apparent gender price differences can depend critically on how “similar products” are defined, offering a methodological framework relevant to clothing price analysis.\n",
    "\n",
    "Taken together, prior work presents mixed evidence regarding gender-based price differences in clothing. Policy reports and journalistic accounts emphasize average price gaps across gendered apparel categories, while critical commentary and academic research highlight the importance of product comparability, data structure, and sensitivity to outliers. These tensions motivate the present study’s research question: **Is there a statistically significant difference in the unit price paid for clothing items associated with women compared to men, and does this pattern hold across independent retail datasets with different data structures and price measurement approaches?**\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Ngabirano, A.-M. (2017). *‘Pink Tax’ forces women to pay more than men.* USA TODAY.  \n",
    "   https://www.usatoday.com\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Bourne, R. (2015). *NYC study finds some evidence of gender price differences—but it certainly isn’t systematic or widespread.* American Enterprise Institute.  \n",
    "   https://www.aei.org/carpe-diem/nyc-study-finds-some-evidence-of-gender-price-differences-but-it-certainly-isnt-systematic-or-widespread/\n",
    "\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Scott, J. (2025). *Gender discrimination in global clothing tariffs.* Global Policy, 16(5), 1063–1074.  \n",
    "   https://doi.org/10.1111/1758-5899.70070\n",
    "\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Moshary, S., Tuchman, A., & Vajravelu, N. (2023). *Gender-based pricing in consumer packaged goods: A pink tax?* Marketing Science, 45(1), 1–14.  \n",
    "   https://doi.org/10.1287/mksc.2023.1452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a8JYba2m_Wo"
   },
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hrl8mcaSm_Wo"
   },
   "source": [
    "We hypothesize that female-associated clothing commands a statistically significantly higher unit price than male-associated clothing. This prediction is supported by prior evidence from the NYC DCA report, which found women's clothing to be approximately 8% more expensive than men's on average. We expect this pattern to manifest both in the price tiers female buyers select and in the labeled prices of women's versus men's apparel products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TclU0znTm_Wp"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7IbJNK7m_Wp"
   },
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T56xNhTDV-Wr"
   },
   "source": [
    "### Data overview\n",
    "\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets.\n",
    "\n",
    "###Dataset #1 — Customer Retail Transaction Dataset\n",
    "  - **Dataset Name** Customer Retail Transaction Dataset\n",
    "  - **Link to the dataset** [Kaggle - Online Shopping Dataset](https://www.kaggle.com/datasets/jacksondivakarr/online-shopping-dataset)\n",
    "  - **Number of observations** 52955\n",
    "  - **Number of variables** 21\n",
    "  - **Description of the variables most relevant to this project**\n",
    "      1. `Product_Description`: The text name of the item (e.g., \"Google Men's 100% Cotton Short Sleeve Hero Tee Black\"). This is the most critical variable because we use keyword extraction on this text to determine the target demographic (Men/Women) and the clothing sub-category (T-shirts/Outerwear).\n",
    "      1. `Product_Category`: Identifies the type of product and supports category-level comparisons.\n",
    "      2. `Avg_Price`: The average selling price of the product, used as a reference price variable.\n",
    "      3. `Quantity`: The number of units purchased in each transaction.\n",
    "      4. `Discount_pct`: Describe promotional discounts and coupon usage, which help explain sources of price variation.\n",
    "      \n",
    "  - **Descriptions of any shortcomings this dataset has with repsect to the project:**\n",
    "\n",
    "      Small Unique Product Sample Size: While the dataset has nearly 53,000 observations, these represent transactions, not unique products. Once the data is filtered strictly to adult clothing and grouped by unique item to establish a \"catalog price,\" the sample size drops drastically.\n",
    "\n",
    "      Misleading Buyer Gender: Although the dataset includes a `Gender` column, it doesn't specifically mean the targer gender of the product, instead it represents the customers' gender, which can be different from the target gender (A man could buy women's T-shirt for his family). Therefore, the buyer's gender cannot be used as a proxy for the product's target demographic, forcing us to rely entirely on product descriptions. However, unlike Amazon, Google Merchandise Store labels the products in a standardized way, which makes the descriptions reliable.\n",
    "\n",
    "#### Dataset #2 — Retail Sales Dataset\n",
    "\n",
    "- **Dataset Name:** Retail Sales Dataset\n",
    "- **Link to the dataset:** [Kaggle - Retail Sales Dataset](https://www.kaggle.com/datasets/mohammadtalib786/retail-sales-dataset)\n",
    "\n",
    "- **Number of observations:** 1,000 transactions\n",
    "- **Number of variables:** 9\n",
    "- **Variables most relevant to this project:**\n",
    "  - `Gender` — Buyer's self-reported gender (`Male` / `Female`). Used as a proxy for the gender that the purchased product is marketed toward (see methodological note in Step 4).\n",
    "  - `Product Category` — One of three categories: `Clothing`, `Electronics`, `Beauty`. We filter to `Clothing` only for this analysis.\n",
    "  - `Price per Unit` — Unit price of the purchased item in USD. Takes 5 discrete values: \\$25, \\$30, \\$50, \\$300, \\$500. This is our primary outcome variable.\n",
    "  - `Quantity` — Number of units purchased per transaction (1–4).\n",
    "  - `Total Amount` — Equals `Price per Unit × Quantity`. Used as a secondary spending measure and consistency cross-check.\n",
    "  - `Age` — Buyer's age (18–64). Used to construct age-group interaction variables.\n",
    "- **Shortcomings with respect to the project:**\n",
    "  - `Gender` records the *buyer's* identity, not the gender that a product is marketed toward. We must rely on the proxy assumption that female buyers purchase female-targeted clothing and vice versa, which introduces measurement error.\n",
    "  - `Price per Unit` is a synthetic discrete variable with only 5 values, not a continuous real-world pricing variable. This limits the precision of price comparisons and requires non-parametric statistical methods.\n",
    "  - The dataset is likely simulated/generated (no source retailer is identified), which means findings may not generalize to real-world retail pricing behavior.\n",
    "  - No product-level attributes (brand, material, style) are available, making it impossible to control for product quality when comparing prices across genders.\n",
    "\n",
    "\n",
    "#### How We Plan to Use These Datasets\n",
    "\n",
    "The two datasets approach the same research question — whether female-associated clothing commands a higher unit price than male-associated clothing — from two complementary perspectives.\n",
    "\n",
    "**Dataset #1 (Online Shopping) examines pricing from the product label perspective.** Within the `Apparel` category, we filter to transactions where `Product_Description` contains explicit gender labels (`Men's` or `Women's`). This allows us to compare `Avg_Price` directly between male-labeled and female-labeled products, without relying on buyer gender as a proxy. This is the stronger, more direct test of the pink tax hypothesis.\n",
    "\n",
    "**Dataset #2 (Retail Sales) examines pricing from the buyer behavior perspective.** We use the buyer's `Gender` to ask whether female buyers consistently select higher `Price per Unit` tiers than male buyers within the `Clothing` category. This captures the consumer side of the same question.\n",
    "\n",
    "Together, the two datasets provide cross-validated evidence: if both the product-label analysis (Dataset #1) and the buyer-behavior analysis (Dataset #2) point in the same direction — female-associated clothing priced higher than male-associated clothing — this convergence strengthens the overall conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFgPHEt9m_Wq",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset #1\n",
    "\n",
    "1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "\n",
    "      **Answer:** The primary metric for our analysis is `Avg_Price`, which represents the unit price of a single clothing item in US Dollars (\\$SSP). \n",
    "\n",
    "In this dataset, clothing prices typically range from around `$10.00` to over `$100.00`, depending on the item type (T-shirts or outerwear). We utilize derived categorical metrics: \n",
    "\n",
    "* **`Product_Gender`**: (Men, Women, Unisex/Other, Kids) extracted from product descriptions to identify the target demographic.\n",
    "* **`Clothing_Type`**: (T-Shirts & Shirts, Outerwear) to ensure we are comparing similar items and controlling for compositional price differences.\n",
    "\n",
    "2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "\n",
    "      answer: There are severak concerns and potential bias with this dataset that we try to avoid.\n",
    "\n",
    "      First is selection bias, This data comes exclusively from the Google Merchandise Store. Therefore, the prices reflect the pricing strategy of a single tech company selling promotional/branded merchandise, rather than a broad, competitive retail market like Target or Amazon. To mitigate this, we introduced another dataset to further explore our research questions.\n",
    "\n",
    "      Second is demographic bias, as the consumers purchasing these items are likely tech-industry employees, developers, or brand enthusiasts, which does not represent the average global consumer. This demographic might have higher disposable income or different purchasing habits. Similar to last bias, an additional dataset would be helpful to this.\n",
    "\n",
    "      Finally, there are sample size and inventory limitations. While the dataset has thousands of transactions, it has a relatively small catalog of unique products. After filtering for explicit \"Men's\" and \"Women's\" items and controlling for product category, our sample sizes are limited (e.g., only 17 unique men's outerwear items and 17 unique women's outerwear items). This limits our statistical power to compare specific products (only 7 products are sold to both men and women)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzrgMIBS9W9e"
   },
   "source": [
    "### Dataset #2\n",
    "\n",
    "1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values less than 70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "\n",
    "2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "\n",
    "    **Answer for 1 and 2 for dataset 2:**\n",
    "    This dataset allows us to investigate consumer behavior by isolating the Clothing category to compare purchasing patterns between male and female shoppers. By analyzing the relationship between unit price, volume, and total expenditure, we can determine if one gender consistently outspends the other or if spending \"peaks\" differently across demographics.\n",
    "\n",
    "    1. Important Metrics and Units: there are 2 metrics we consider:\n",
    "      - Total Amount (USD): This represents the final revenue of a transaction and serves as our primary \"spending\" metric. In the clothing category, \"Normal\" values range from `$50` to `$300`. A value > `$500` indicates a \"Premium Purchase\" while values < \\$25 indicate \"Accessory Purchases\"—e.g., socks or basic tees. For our analysis, comparing the Average Total Amount is crucial because the \"Total Sum\" would be biased by the fact that there are 3 more men than women in our sample.\n",
    "\n",
    "      - Price per Unit (USD): This indicates the cost of a single clothing item. Values of \\$25 to \\$100 represent \"Standard Retail\" pricing. A Price per Unit of \\$500 is the maximum in this dataset and represents \"Luxury Tier\" goods. We use this to see if one gender prefers fewer, more expensive items versus the other gender's preference for multiple, cheaper items.\n",
    "\n",
    "    2. Major Concerns and Shortcomings:\n",
    "      - The dataset is small size where we have 351 clothing transactions (177 male, 174 female) after data cleaning;\n",
    "      - Another major concern for our specific question is the massive gap between the mean (around 400 both male and female) and median (around 130 both male and female). This suggests that a very small number of women making \"Luxury Tier\" purchases are pulling the average up significantly. If we only look at the average, we might incorrectly conclude that \"all women spend more,\" when in reality, the typical median man `$150` actually spends more than the typical median woman `$120`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iTmUA9-GA5v"
   },
   "source": [
    "3. Use the cell below to\n",
    "    1. load the dataset\n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsuPTYC6TmFA"
   },
   "source": [
    "## SETUP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRGtaytnVE9C"
   },
   "source": [
    "\n",
    "This section originally included code to mount Google Drive in order to load CSV files during early development. Please note that the Google Drive–based loading code is no longer required and can be safely ignored by the TA. All necessary CSV files have now been added directly to the GitHub repository under the data/ directory to ensure full reproducibility and accessibility.\n",
    "\n",
    "For this project, we use the following Python libraries for data loading, cleaning, transformation, and visualization:\n",
    "\n",
    "pandas for data manipulation\n",
    "\n",
    "numpy for numerical operations\n",
    "\n",
    "matplotlib and seaborn for visualization\n",
    "\n",
    "scipy.stats for normality testing and non-parametric statistical analysis\n",
    "\n",
    "The current and intended method for loading data is to read CSV files directly from the repository using relative paths, rather than from Google Drive. This allows the notebook to run locally or after cloning the GitHub repository without any additional permissions or setup.\n",
    "\n",
    "- To avoid any error happend on importing google drive or github .csv files, here is our shared csv files link. If some unexpected issues, please feel free to download from this link and load in your local machine:\n",
    "\n",
    "- link 1 for file.csv: https://drive.google.com/file/d/11g8ESt7rc7oO9Uv3oH0cUtxgEnSmKKjs/view?usp=sharing\n",
    "\n",
    "- link 2 for retail_sales_dataset.csv: https://drive.google.com/file/d/19xVd9paTrab7NIILxkqQnxy1SGpwqbEB/view?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ROOT = Path.cwd()\n",
    "\n",
    "file1_path = ROOT / \"data\" / \"00-raw\" / \"retail_sales_dataset.csv\"\n",
    "file2_path = ROOT / \"data\" / \"00-raw\" / \"file.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1771486850374,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "MxqUkU9NaWEi",
    "outputId": "13bf3d3b-2926-4b6b-b167-6205d15c048a"
   },
   "outputs": [],
   "source": [
    "#Google Drive–based loading code is no longer required and this cell can be ignored by TA.\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#file1_path = '/content/drive/MyDrive/cogs108-136/retail_sales_dataset.csv'\n",
    "#file2_path = '/content/drive/MyDrive/cogs108-136/file.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7H--vTEaYEz"
   },
   "outputs": [],
   "source": [
    "#Google Drive–based loading code is no longer required and this cell can be ignored by TA.\n",
    "#!ls /content/drive/MyDrive/cogs108-136/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check path and if csv file exist in Github path\n",
    "print(\"Working dir:\", ROOT)\n",
    "print(\"File1 exists:\", file1_path.exists())\n",
    "print(\"File2 exists:\", file2_path.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDIVHoPxaDeL"
   },
   "source": [
    "# Dataset #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAXfQMH-g2mZ"
   },
   "source": [
    "This section loads Dataset #1 into pandas and prints out the dataset size, column names, and product categories. The goal is just to get a feel for what the data looks like before cleaning anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1771486850672,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "-V6RikZwwg9V",
    "outputId": "f067493b-6754-4997-955c-d45bef35db91"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Load raw dataset\n",
    "df = pd.read_csv(file2_path)\n",
    "\n",
    "print(\"Initial Data Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "# Check unique product categories to identify clothing-related items\n",
    "print(\"\\nUnique Product Categories:\")\n",
    "print(df['Product_Category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcs-BY77iSxR"
   },
   "source": [
    "### Data cleaning #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Cb5m2ggaHJQ"
   },
   "source": [
    "At this point, the dataset is filtered to only include clothing-related categories like Apparel and Headgear. This helps remove unrelated products early so the rest of the analysis stays focused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1771486850672,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "SUpGIS4aRV_K",
    "outputId": "0693306f-2050-4b33-89b7-4772e9e4ab66"
   },
   "outputs": [],
   "source": [
    "clothing_df = df[df['Product_Category'].isin(['Apparel', 'Headgear'])].copy()\n",
    "\n",
    "print(f\"Filtered Data Shape: {clothing_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Sjysn6HaLjf"
   },
   "source": [
    "This step handles the basic data cleaning. Rows missing important information are dropped, missing coupon and discount values are filled in with reasonable defaults, duplicates are removed, and transaction dates are converted to a proper datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1771486850684,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "IapdAIeZRZ8T",
    "outputId": "c5ea8e9b-c442-4293-ed79-c0d65eddfe42"
   },
   "outputs": [],
   "source": [
    "clothing_df.dropna(subset=['Product_Description', 'Avg_Price', 'Transaction_ID'], inplace=True)\n",
    "\n",
    "# Fill missing values in non-critical columns\n",
    "# 'Coupon_Code' likely has NaNs where no coupon was used\n",
    "clothing_df['Coupon_Code'] = clothing_df['Coupon_Code'].fillna('No Coupon')\n",
    "clothing_df['Discount_pct'] = clothing_df['Discount_pct'].fillna(0.0)\n",
    "\n",
    "# Remove duplicate rows if any\n",
    "clothing_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert Date column to datetime objects\n",
    "clothing_df['Transaction_Date'] = pd.to_datetime(clothing_df['Transaction_Date'])\n",
    "\n",
    "print(\"Data cleaned of missing values and duplicates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IK7beBTHaP_B"
   },
   "source": [
    "Here I create a function that looks at product descriptions and assigns a gender label based on keywords. Products are categorized as Men, Women, Kids, or Unisex/Other, which allows us to compare how products are marketed across genders later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1771486850728,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "0rEGwY3bRlW_",
    "outputId": "496bc3c7-2341-4249-f86d-b9a9ae7cb347"
   },
   "outputs": [],
   "source": [
    "def extract_product_gender(description):\n",
    "    # Convert description to lowercase for easier searching\n",
    "    desc = str(description).lower()\n",
    "\n",
    "    # Define keywords\n",
    "    if any(x in desc for x in ['youth', 'toddler', 'infant', 'onesie', 'kids']):\n",
    "        return 'Kids'\n",
    "    elif 'women' in desc:\n",
    "        return 'Women'\n",
    "    elif 'men' in desc:\n",
    "        return 'Men'\n",
    "    else:\n",
    "        return 'Unisex/Other'\n",
    "\n",
    "# Apply the function to create a new column\n",
    "clothing_df['Product_Gender'] = clothing_df['Product_Description'].apply(extract_product_gender)\n",
    "\n",
    "# Check the distribution\n",
    "print(clothing_df['Product_Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeDaHj7ou9LR"
   },
   "source": [
    "We filter clothing_df to get the products for only 'Men' and 'Women'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0pb5yFVjtwo"
   },
   "outputs": [],
   "source": [
    "adult_clothing = clothing_df[clothing_df['Product_Gender'].isin(['Men', 'Women'])].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8kohoFovggM"
   },
   "source": [
    "We categorize the products into 'T-Shirts & Shirts', 'Outerwear', 'Headgear', and 'Other'. We then drop 'Headgear' (since it is entirely unisex) and 'Other' to focus on clear gendered categories. Finally, because the same item might have been sold at different prices due to discounts, we calculate the median price for each unique product to establish a single standard price. This ensures that our statistical tests compare the store's standard baseline price for each item, rather than being skewed by purchase frequency or temporary discounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1771486850811,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "D5uMQHXily9g",
    "outputId": "2db71952-3c1d-4ac6-fd80-348c5f7d7037"
   },
   "outputs": [],
   "source": [
    "def get_clothing_type(desc):\n",
    "    desc = str(desc).lower()\n",
    "    if any(word in desc for word in ['tee', 't-shirt', 'shirt', 'polo']):\n",
    "        return 'T-Shirts & Shirts'\n",
    "    elif any(word in desc for word in ['hoodie', 'jacket', 'sweatshirt', 'pullover', 'vest', 'softshell']):\n",
    "        return 'Outerwear'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the categorization\n",
    "adult_clothing['Clothing_Type'] = adult_clothing['Product_Description'].apply(get_clothing_type)\n",
    "\n",
    "# Drop 'Other' if you only want the main clean categories\n",
    "analysis_df = adult_clothing[adult_clothing['Clothing_Type'] != 'Other'].copy()\n",
    "\n",
    "# Keep only unique products so we don't count the same shirt 500 times\n",
    "unique_catalog = analysis_df.groupby(['Product_Description', 'Product_Gender', 'Clothing_Type'])['Avg_Price'].median().reset_index()\n",
    "\n",
    "print(unique_catalog.groupby(['Clothing_Type', 'Product_Gender']).size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLDRynDU8kvq"
   },
   "source": [
    "Here is the EDA visualization. It shows the actual distribution of prices between Men's and Women's clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1771488708302,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "XwKqP6t68Yyi",
    "outputId": "a60f0f2f-cd51-4833-d431-26745ab38180"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# A boxplot shows the median, spread, and outliers of the prices\n",
    "sns.boxplot(data=unique_catalog, x='Clothing_Type', y='Avg_Price', hue='Product_Gender', palette=['#3498db', '#e74c3c'])\n",
    "\n",
    "plt.title('Price Distribution of Unique Items: Men vs. Women')\n",
    "plt.xlabel('Clothing Sub-Category')\n",
    "plt.ylabel('Standard Item Price (USD)')\n",
    "plt.legend(title='Target Gender')\n",
    "\n",
    "# Format the y-axis to show dollar signs\n",
    "import matplotlib.ticker as ticker\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('${x:,.2f}'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CP7NGuuUXcV"
   },
   "source": [
    "# Dataset #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kF8v_Zg4XWYt"
   },
   "source": [
    "### Step 1 — Load Dataset and Understand Data Structure\n",
    "\n",
    "We load the retail sales dataset and inspect its structure. The dataset contains **1,000 rows and 9 columns**, recording retail transactions across three product categories: Clothing, Electronics, and Beauty. Each row represents a single transaction.\n",
    "\n",
    "Key variable notes:\n",
    "- **`Gender`**: Records the *buyer's* gender (`Male`/`Female`), **not** the gender a product is marketed toward. This distinction is critical and will be addressed explicitly in Step 4.\n",
    "- **`Price per Unit`**: Takes only 5 discrete values (\\$25, \\$30, \\$50, \\$300, \\$500), indicating a simplified/synthetic dataset. This affects which statistical methods are appropriate.\n",
    "- **`Total Amount`**: Equals `Price per Unit × Quantity`, serving as a consistency check.\n",
    "- **`Product Category`**: Three categories — Clothing, Electronics, Beauty. Our analysis focuses exclusively on Clothing.\n",
    "\n",
    "**Shortcoming**: Because `Gender` reflects buyer identity rather than product-target gender, our analysis relies on a proxy assumption (detailed in Step 4), which is a key limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1771486851464,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "1heyR4iguPGH",
    "outputId": "97a33176-f84f-48e6-fe42-91a3dbf859ea"
   },
   "outputs": [],
   "source": [
    "# Load the first dataset\n",
    "df_retail = pd.read_csv(file1_path)\n",
    "\n",
    "# Load the second dataset\n",
    "df_other = pd.read_csv(file2_path)\n",
    "\n",
    "# Preview the first few rows of the retail data\n",
    "df_retail.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ro5prgSYDlKY"
   },
   "source": [
    "Then we collect how many data totally in this dataset with variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1771486851474,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "Z7U-zAA5yGNu",
    "outputId": "2e85c0b8-811b-4362-85ff-415d81c72a52"
   },
   "outputs": [],
   "source": [
    "# Basic dataset size\n",
    "df_retail.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5-EHLS4xHE3"
   },
   "source": [
    "Data cleaning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vZP3LQlyQCX"
   },
   "source": [
    "### Step 2 — Data Quality Check\n",
    "\n",
    "Before any filtering or analysis, we verify data integrity across four dimensions:\n",
    "\n",
    "1. **Missing values** — check for NaN in all columns.\n",
    "2. **Duplicate rows** — check for repeated Transaction IDs.\n",
    "3. **Categorical consistency** — confirm `Gender` contains only `Male`/`Female` and `Product Category` has no typos or unexpected values.\n",
    "4. **Outliers in numeric columns** — inspect `Price per Unit`, `Quantity`, and `Total Amount` for suspicious entries.\n",
    "\n",
    "If the dataset is found to be clean (zero missing values, no duplicates, consistent categories), we document this as a finding rather than silently skipping the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1771486851481,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "SX8iSdMZyKbb",
    "outputId": "a6380010-1a48-4e38-dee4-bde48a2cb077",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_retail.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Kr8YSdZytKK"
   },
   "source": [
    "### Step 3: Filtering your dataset to focus only on clothing\n",
    "\n",
    "Our research question focuses specifically on clothing purchases and whether female buyers pay higher prices per unit than male buyers. We therefore filter the full dataset to retain only rows where `Product Category == 'Clothing'`, reducing the working dataset from **1,000 rows to 351 rows**.\n",
    "\n",
    "Electronics and Beauty transactions are excluded from all subsequent analysis. After filtering, we verify gender balance: 174 Female and 177 Male transactions — sufficiently balanced for group comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1771486851493,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "dbcu_p9UH81w",
    "outputId": "ebee3dd7-917b-45c2-b464-666c462b4684"
   },
   "outputs": [],
   "source": [
    "# Strip whitespace to prevent mismatch on filter\n",
    "df_retail['Product Category'] = df_retail['Product Category'].str.strip()\n",
    "\n",
    "#Filter to Clothing only\n",
    "clothing_df = df_retail[df_retail['Product Category'] == 'Clothing'].copy()\n",
    "clothing_df = clothing_df.reset_index(drop=True)\n",
    "\n",
    "print(f'Full dataset rows:     {len(df_retail)}')\n",
    "print(f'Clothing-only rows:    {len(clothing_df)}')\n",
    "print()\n",
    "print('Gender balance in Clothing subset:')\n",
    "print(clothing_df['Gender'].value_counts())\n",
    "print()\n",
    "clothing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02I5wv62y461"
   },
   "source": [
    "### Step 4 — Defining the Gender Variable\n",
    "\n",
    "This is the most consequential methodological decision in our data cleaning process. Since the dataset records **buyer gender** rather than the gender a product is marketed toward, we must make an explicit assumption to proceed.\n",
    "\n",
    "**Assumption adopted:** We treat buyer gender as a proxy for the gender that the purchased product is marketed toward — i.e., we assume female buyers predominantly purchase women's clothing and male buyers predominantly purchase men's clothing. This is a simplifying assumption that introduces potential measurement error, and we acknowledge it as a key limitation of this analysis.\n",
    "\n",
    "Under this assumption, our research question becomes: *Do female buyers tend to pay higher prices per unit for clothing compared to male buyers?* This allows us to use `Gender` as the independent variable and `Price per Unit` as the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1771486851520,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "_lqXrpDiIyHg",
    "outputId": "483dcedc-4527-4d59-8735-33d8165d494e"
   },
   "outputs": [],
   "source": [
    "#check gender balance and compute basic price statistics by gender\n",
    "gender_counts = clothing_df['Gender'].value_counts()\n",
    "print('Transaction count by gender:')\n",
    "print(gender_counts)\n",
    "print()\n",
    "\n",
    "# summary statistics: Price per Unit by Gender\n",
    "price_stats = clothing_df.groupby('Gender')['Price per Unit'].agg(['mean', 'median', 'std', 'count'])\n",
    "price_stats.columns = ['Mean Price', 'Median Price', 'Std Dev', 'Count']\n",
    "print('Price per Unit statistics by Gender:')\n",
    "print(price_stats.round(2))\n",
    "print()\n",
    "\n",
    "#total amount statistics by Gender (for reference)\n",
    "spend_stats = clothing_df.groupby('Gender')['Total Amount'].agg(['mean', 'median', 'std'])\n",
    "spend_stats.columns = ['Mean Total Spend', 'Median Total Spend', 'Std Dev']\n",
    "print('Total Amount statistics by Gender:')\n",
    "print(spend_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2Djv9YbYYJw"
   },
   "source": [
    "Since our group sizes are slightly different, 177 males vs. 174 females, we consider using average to analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1771486851896,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "3r1VTXoj6Uab",
    "outputId": "159491a0-4687-480c-87be-b4c894243d14"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.histplot(\n",
    "    data=clothing_df,\n",
    "    x='Total Amount',\n",
    "    hue='Gender',\n",
    "    hue_order=['Female', 'Male'],\n",
    "    palette={'Female': 'tab:orange', 'Male': 'tab:blue'},\n",
    "    kde=True,\n",
    "    element=\"step\"\n",
    ")\n",
    "\n",
    "plt.title('Distribution of Total Amount by Gender in Clothing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T43NiLn55wnl"
   },
   "source": [
    "### Step 5 — Inspect Price Distribution by Gender\n",
    "\n",
    "We examine how purchases are distributed across the 5 price tiers—**`$25`, `$30`, `$50`, `$300`, and `$500`**—separately for Female and Male buyers. \n",
    "\n",
    "This step is necessary before choosing a statistical test: \n",
    "* Because **Price per Unit** is ordinal and discrete rather than continuous, we need to verify whether the distribution is approximately normal or whether non-parametric tests are more appropriate.\n",
    "* We use frequency tables and bar charts to visualize the distribution. \n",
    "\n",
    "If the proportion of Female buyers in the `$300` and `$500` tiers is visibly higher than that of Male buyers, this provides preliminary visual evidence consistent with our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1771486852349,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "vwh0Sar9xa7f",
    "outputId": "b40d32b2-bc7d-4c7a-8afb-3693e62e4a1b"
   },
   "outputs": [],
   "source": [
    "#5a). frequency table: count of purchases per price tier by gender ---\n",
    "price_gender_counts = (\n",
    "    clothing_df.groupby(['Gender', 'Price per Unit'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "print('=== Transaction Counts by Gender x Price Tier ===')\n",
    "print(price_gender_counts)\n",
    "print()\n",
    "\n",
    "#5b :proportion table: what % of each gender falls in each price tier\n",
    "price_gender_pct = price_gender_counts.div(price_gender_counts.sum(axis=1), axis=0) * 100\n",
    "print('=== Proportion (%) by Gender x Price Tier ===')\n",
    "print(price_gender_pct.round(1))\n",
    "print()\n",
    "\n",
    "#5(c). Bar chart: side-by-side proportions per price tier\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "#left: raw counts\n",
    "price_gender_counts.T.plot(kind='bar', ax=axes[0], color=['#F4A582', '#92C5DE'], edgecolor='black')\n",
    "axes[0].set_title('Transaction Count by Price Tier and Gender', fontsize=12)\n",
    "axes[0].set_xlabel('Price per Unit ($)')\n",
    "axes[0].set_ylabel('Number of Transactions')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "axes[0].legend(title='Gender')\n",
    "\n",
    "#right: proportions\n",
    "price_gender_pct.T.plot(kind='bar', ax=axes[1], color=['#F4A582', '#92C5DE'], edgecolor='black')\n",
    "axes[1].set_title('Proportion (%) by Price Tier and Gender', fontsize=12)\n",
    "axes[1].set_xlabel('Price per Unit ($)')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "axes[1].legend(title='Gender')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#5(d)normality check: since Price per Unit is discrete/ordinal, ---\n",
    "# we verify it is NOT normally distributed => use non-parametric tests\n",
    "from scipy import stats\n",
    "\n",
    "female_prices = clothing_df[clothing_df['Gender'] == 'Female']['Price per Unit']\n",
    "male_prices   = clothing_df[clothing_df['Gender'] == 'Male']['Price per Unit']\n",
    "\n",
    "stat_f, p_f = stats.shapiro(female_prices)\n",
    "stat_m, p_m = stats.shapiro(male_prices)\n",
    "print(f'Shapiro-Wilk test (Female): W={stat_f:.4f}, p={p_f:.4e}')\n",
    "print(f'Shapiro-Wilk test (Male):   W={stat_m:.4f}, p={p_m:.4e}')\n",
    "print()\n",
    "print('Since price tiers are discrete (only 5 values), the distribution is')\n",
    "print('NOT continuous/normal => Mann-Whitney U test is appropriate for Step 7.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uNZuD8O54dZ"
   },
   "source": [
    "###Step 6 — Create New Variables\n",
    "\n",
    "We engineer three new variables to enrich the analysis:\n",
    "Verified Price per Unit — computed as Total Amount / Quantity. This serves as a cross-check against the existing Price per Unit column to identify any inconsistent transactions. Rows where the two values do not match are flagged for inspection.\n",
    "High-value Purchase Flag — a binary indicator variable where 1 = Price per Unit >= 300 and 0 otherwise. This converts the price variable into a format suitable for logistic regression or chi-square testing, allowing us to ask: are female buyers significantly more likely than male buyers to make a high-value clothing purchase?\n",
    "Multi-item Purchase Flag — a binary indicator where 1 = Quantity > 1 and 0 otherwise. This captures whether a buyer purchased more than one item in a single transaction, which may reflect a secondary dimension of spending behavior that differs by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1771486852389,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "xXmA2t6yIKxF",
    "outputId": "f0146d72-5785-47ad-9760-a276b74c617d"
   },
   "outputs": [],
   "source": [
    "#Calculate min and max for specific columns in the clothing dataset\n",
    "min_max_stats = clothing_df[['Total Amount', 'Price per Unit']].agg(['min', 'max'])\n",
    "\n",
    "print(\"Clothing Category: Range of Prices and Totals\")\n",
    "print(min_max_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1771486852768,
     "user": {
      "displayName": "Xuanye Wang",
      "userId": "04861114243031515122"
     },
     "user_tz": 480
    },
    "id": "ZUXrqWZ_832Z",
    "outputId": "42d4c143-9f8a-435c-8f54-d6bdb6bb499b"
   },
   "outputs": [],
   "source": [
    "#6a) verified Price per Unit (cross-check)\n",
    "clothing_df = clothing_df.copy()  # avoid SettingWithCopyWarning\n",
    "clothing_df['Verified Price per Unit'] = clothing_df['Total Amount'] / clothing_df['Quantity']\n",
    "\n",
    "#flag inconsistent rows (should be 0 if data is clean)\n",
    "inconsistent = clothing_df[\n",
    "    clothing_df['Verified Price per Unit'] != clothing_df['Price per Unit']\n",
    "]\n",
    "print(f'Inconsistent rows (Verified != Original): {len(inconsistent)}')\n",
    "if len(inconsistent) > 0:\n",
    "    print(inconsistent[['Gender', 'Quantity', 'Price per Unit', 'Total Amount', 'Verified Price per Unit']])\n",
    "print()\n",
    "\n",
    "# 6b. High-value Purchase Flag\n",
    "#1 = Price per Unit >= $300 (high-tier: $300 or $500),\n",
    "#0 = otherwise\n",
    "clothing_df['High_Value_Flag'] = (clothing_df['Price per Unit'] >= 300).astype(int)\n",
    "\n",
    "print('=== High-Value Purchase Flag by Gender ===')\n",
    "hv_table = clothing_df.groupby(['Gender', 'High_Value_Flag']).size().unstack(fill_value=0)\n",
    "hv_table.columns = ['Low-Value (< $300)', 'High-Value (>= $300)']\n",
    "hv_table['High-Value Rate (%)'] = (\n",
    "    hv_table['High-Value (>= $300)'] /\n",
    "    hv_table.sum(axis=1) * 100\n",
    ").round(1)\n",
    "print(hv_table)\n",
    "print()\n",
    "\n",
    "# 6c. Multi-item Purchase Flag\n",
    "# 1 -> bought more than 1 item in this transaction, 0 ->single item\n",
    "clothing_df['Multi_Item_Flag'] = (clothing_df['Quantity'] > 1).astype(int)\n",
    "\n",
    "print('=== Multi-Item Purchase Flag by Gender ===')\n",
    "mi_table = clothing_df.groupby(['Gender', 'Multi_Item_Flag']).size().unstack(fill_value=0)\n",
    "mi_table.columns = ['Single Item', 'Multi Item']\n",
    "mi_table['Multi-Item Rate (%)'] = (\n",
    "    mi_table['Multi Item'] /\n",
    "    mi_table.sum(axis=1) * 100\n",
    ").round(1)\n",
    "print(mi_table)\n",
    "print()\n",
    "\n",
    "#6(d) visualization of the two flags\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "#High-value rate by gender\n",
    "hv_rate = clothing_df.groupby('Gender')['High_Value_Flag'].mean() * 100\n",
    "hv_rate.plot(kind='bar', ax=axes[0], color=['#F4A582', '#92C5DE'], edgecolor='black', width=0.5)\n",
    "axes[0].set_title('High-Value Purchase Rate by Gender (>= $300)', fontsize=11)\n",
    "axes[0].set_ylabel('Rate (%)')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "axes[0].set_ylim(0, 100)\n",
    "for p in axes[0].patches:\n",
    "    axes[0].annotate(f'{p.get_height():.1f}%',\n",
    "                     (p.get_x() + p.get_width()/2, p.get_height() + 1),\n",
    "                     ha='center', fontsize=10)\n",
    "\n",
    "#multi-item rate by gender\n",
    "mi_rate = clothing_df.groupby('Gender')['Multi_Item_Flag'].mean() * 100\n",
    "mi_rate.plot(kind='bar', ax=axes[1], color=['#F4A582', '#92C5DE'], edgecolor='black', width=0.5)\n",
    "axes[1].set_title('Multi-Item Purchase Rate by Gender (Qty > 1)', fontsize=11)\n",
    "axes[1].set_ylabel('Rate (%)')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "axes[1].set_ylim(0, 100)\n",
    "for p in axes[1].patches:\n",
    "    axes[1].annotate(f'{p.get_height():.1f}%',\n",
    "                     (p.get_x() + p.get_width()/2, p.get_height() + 1),\n",
    "                     ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f1ylHQSm_Wr"
   },
   "source": [
    "## Ethics\n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "    > Since the dataset regarding Walmart customer involves human subjects, and we did not obtain direct consent from them. However, the data is publicly available on Kaggle and the human subjects are anonymized. We will continue using this dataset under the assumption that the data was collected in accordance with privacy laws or have the consent from the customers in advance.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?()\n",
    "\n",
    "    > Although we have two datasets from different platforms, we must acknowledge that these populations are different (Amazon online vs. Walmart in-store). This would introduce collection bias, as the demographics of online shoppers may differ from in-store shoppers in terms of income or location. We will mitigate this by analyzing these datasets separately where appropriate and avoiding broad generalizations about \"all consumers\" based solely on these specific platforms.\n",
    "\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "    > Although the Walmart dataset doesn't use specific names, it contains Gender, Age, and User_ID. To minimize exposure of personally identifiable information, we will remove the User_ID column immediately upon importing the data, as it is not necessary for our project. Furthermore, we will only report summary statistics and won't disclose any specific information.\n",
    "\n",
    " - [ ] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [ ] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [ ] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "    > Our analysis compares products for \"Men\" and \"Women\" to test the specific hypothesis of the Pink Tax. We acknowledge that this excludes non-binary gender identities from our project. While this binary framework is necessary to answer our specific research question regarding gender-based pricing disparities, we will note this limitation in our discussion to avoid implying that all consumer products must fit into these two categories and encourage future work on top of our project.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "    > There is a risk of confirmation bias in how we categorize products (e.g., assuming a blue razor is for men and a pink one is for women). To mitigate this, we will rely strictly on the product titles (e.g., \"Men\", \"Women\", \"For Him\", \"For Her\", \"Male\", \"Female\") for this step. We will also perform sanity checks to ensure we aren't inadvertently selecting expensive women's brands and cheap men's brands, which would artificially create the price difference.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "    > In our visualizations (particularly bar charts comparing Men’s vs. Women’s prices), we will ensure that axes are scaled appropriately (starting at zero where possible) to avoid exaggerating small price differences. We will also include metadata, such as standard deviation, to represent the data honestly.\n",
    "\n",
    " - [ ] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "    > Because we will filter a massive dataset down to a specific dataset for our project, we will document each step for transparency. This ensures that our \"Pink Tax\" label is reproducible and that outside observers can verify we didn't \"cherry-pick\" items to force a result.\n",
    "\n",
    "### D. Modeling\n",
    " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "   > One potential limitation is that our model may be affected by confounding variables such as ingredients that might increase costs. We will clearly communicate that a \"price difference\" does not automatically prove \"price discrimination\" without a full ingredient analysis, which is outside the scope of this project. We will phrase our conclusion carefully to avoid overstating the implications.\n",
    "\n",
    "### E. Deployment\n",
    " - [ ] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [ ] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [ ] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [ ] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "462QTXsgm_Wr"
   },
   "source": [
    "## Team Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FImPcX-m_Wr"
   },
   "source": [
    "### Team Members\n",
    "\n",
    "- Yilin Cai  \n",
    "- Nicole Liu  \n",
    "- Xuanye Wang  \n",
    "- Lianshi Deng  \n",
    "- Jiangxi Fu  \n",
    "\n",
    "**Team Expectations(agreed by all team members)**\n",
    "---\n",
    "\n",
    "* *Team Expectation 1:* All group members agree to follow the COGS 108 Team Policies and work collaboratively throughout the quarter.\n",
    "\n",
    "* *Team Expectation 2:* Our team will meet in person every Monday at 5:00 PM on the second floor of Geisel Library to discuss project progress and next steps. If a member cannot attend, they must notify the group at least 12 hours in advance.\n",
    "\n",
    "* *Team Expectation 3:* We will primarily communicate through a group chat, and all members are expected to check and respond to messages regularly to stay on the same page.\n",
    "\n",
    "* *Team Expectation 4:* Tasks will be assigned based on individual interest and voluntary commitment. Members are expected to actively participate in discussions and contribute to their assigned sections.\n",
    "\n",
    "* *Team Expectation 5:* We encourage open and respectful discussion during meetings. If disagreements arise, we will address them through constructive group discussion.\n",
    "\n",
    "* *Team Expectation 6:* If a conflict cannot be resolved internally, we will consult the TA for guidance.\n",
    "\n",
    "* *Team Expectation 7:* We will use GitHub for version control. All members are expected to follow proper workflow, including creating new branches, opening pull requests, resolving conflicts, assigning a teammate for review, and merging into the main branch after approval.\n",
    "\n",
    "* *Team Expectation 8:* If conflicts arise regarding project direction or workload, we will discuss them openly during meetings rather than letting frustration build.\n",
    "\n",
    "* *Team Expectation 9:* If a resolution still cannot be reached after discussion, we will seek assistance from the TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyJP33zNm_Wr"
   },
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeCIO0M7m_Wr"
   },
   "source": [
    "What we updated: We elaborated on the specific focus of each check-in. We updated our timeline to include specific tasks e.g. data cleaning, category isolation, and statistical skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnwknY_4vgMm"
   },
   "source": [
    "\n",
    "\n",
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **1/27** | 6 PM | Formed group and established communication channels. | Review pre-projects from different categories. Analyze advantages/disadvantages and finalize the primary research method and topic direction. |\n",
    "| **2/02** | 5 PM | Conducted background research on retail trends and gender spending habits. | Finalize the project proposal draft. Review project strengths/weaknesses and confirm initial task assignments for each teammate. |\n",
    "| **2/09** | 5 PM | Brainstormed specific research questions. Located the \"Retail Sales Dataset\" on Kaggle. | Review the draft proposal. Discuss data preprocessing methods and ensure dataset variables align with our \"Gender vs. Clothing\" hypothesis. |\n",
    "| **2/17** | 6 PM | Finalized project proposal for submission. | Assign specific data wrangling tasks. Discuss the structure of the shared Google Drive folder and set up Colab environments for the team. Finish checkpoint 1- data cleaning, category isolation, and discuss statiscal skewness |\n",
    "| **2/23** | 5 PM | Completed Data Checkpoint. Isolated \"Clothing\" category and performed initial cleaning (handling NaNs and type conversion). | Discuss the impact of outliers (Mean vs. Median). Assign roles for the Exploratory Data Analysis (EDA) and visualization phase. |\n",
    "| **3/02** | 5 PM | Generate initial visualizations (histograms and boxplots). Run descriptive statistics to compare Male vs. Female average spending. | Evaluate data presentation ideas. If results are skewed by outliers, decide on a final strategy (keeping vs. dropping) and begin drafting the Analysis section. |\n",
    "| **3/09** | 5 PM | Complete full statistical analysis and secondary research to support findings. | Finalize all charts and write descriptions explaining correlations. Begin assembling the final slideshow and project narrative. |\n",
    "| **3/17** | 11:59 PM | Perform final review of the notebook, results, and video presentation. | Conduct a final submission checklist. Ensure all team members have contributed to the documentation and turn in the Final Project. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPxKbxpOwBWA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
